<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Research and Publications - Ethan Wang">
    <title>Research - Ethan Wang</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-logo">Ethan Wang</a>
            <ul class="nav-menu">
                <li class="nav-item">
                    <a href="index.html" class="nav-link">Home</a>
                </li>
                <li class="nav-item">
                    <a href="research.html" class="nav-link active">Research</a>
                </li>
                <li class="nav-item">
                    <a href="cv.html" class="nav-link">CV</a>
                </li>
            </ul>
        </div>
    </nav>

    <main class="container">
        <section class="research-overview">
            <h1>Research</h1>
            <p class="research-intro">
                My research focuses on [general description of your research area]. I am particularly interested in
                [specific problems or questions you're investigating]. My work combines [methodologies or approaches you
                use] to [what you hope to achieve or understand].
            </p>
        </section>

        <section class="research-interests">
            <h2>Research Interests</h2>
            <ul class="interests-list">
                <li>Privacy</li>
                <li>AI Bot Detection</li>
                <li>AI Browsers/Web Browsing</li>
            </ul>
        </section>

        <section class="publications-section">
            <h2>Publications & Preprints</h2>

            <div class="publication">
                <h3 class="paper-title">Security of AI Agents</h3>
                <p class="paper-authors">
                    Yifeng He, <strong>Ethan Wang</strong>, Yuyang Rong, Zifei Cheng, Hao Chen
                </p>
                <p class="paper-venue">
                    <em>IEEE/ACM International Workshop on Responsible AI Engineering (RAIE)</em>, 2025
                </p>
                <p class="paper-abstract">
                    <!-- [Brief abstract or description of the paper. One or two sentences explaining what the paper is about
                    and its main contribution.] -->
                    AI agents have been boosted by large language models. AI agents can function as intelligent
                    assistants and complete tasks on behalf of their users with access to tools and the ability to
                    execute commands in their environments. Through studying and experiencing the workflow of typical AI
                    agents, we have raised several concerns regarding their security. These potential vulnerabilities
                    are not addressed by the frameworks used to build the agents, nor by research aimed at improving the
                    agents. In this paper, we identify and describe these vulnerabilities in detail from a system
                    security perspective, emphasizing their causes and severe effects. Furthermore, we introduce defense
                    mechanisms corresponding to each vulnerability with design and experiments to evaluate their
                    viability. Altogether, this paper contextualizes the security issues in the current development of
                    AI agents and delineates methods to make AI agents safer and more reliable.
                </p>
                <div class="paper-links">
                    <a href="https://ieeexplore.ieee.org/document/11029384" class="paper-link" target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2406.08689" class="paper-link" target="_blank">[arXiv]</a>
                    <!-- <a href="[code-url]" class="paper-link" target="_blank">[Code]</a> -->
                    <!-- <a href="[project-page-url]" class="paper-link" target="_blank">[Project Page]</a> -->
                </div>
            </div>

            <div class="publication">
                <h3 class="paper-title">UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large
                    Language Models for Program Testing
                </h3>
                <p class="paper-authors">
                    Yifeng He, Jiabo Huang, Yuyang Rong, Yiwen Guo, <strong>Ethan Wang</strong>, Hao Chen
                </p>
                <p class="paper-venue">
                    <em>ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA)</em>, 2024
                </p>
                <p class="paper-abstract">
                    <!-- [Brief abstract or description of the paper. One or two sentences explaining what the paper is about
                    and its main contribution.] -->
                    The remarkable capability of large language models (LLMs) in generating high-quality code has drawn
                    increasing attention in the
                    software testing community. However, existing code LLMs often
                    demonstrate unsatisfactory capabilities in generating accurate, complete tests since they were
                    trained on code snippets collected without differentiating between code for testing and for other
                    purposes.
                    In this paper, we present a large-scale dataset, UniTSyn, which can
                    enhance LLMs for Unit Test Synthesis. Associating tests with the
                    tested functions is crucial for LLMs to infer the expected behavior
                    and the logic paths to be verified. By leveraging Language Server
                    Protocol, UniTSyn achieves the challenging goal of collecting focaltest pairs without per-project
                    execution setups or per-language
                    heuristics, which tend to be fragile and dif√ècult to scale. Containing
                    2.7 million focal-test pairs across five mainstream programming
                    languages, it can enhance the test generation ability of LLMs. Our
                    experiments demonstrate that, by building an autoregressive LLM
                    based on UniTSyn, we can achieve significant benefits in learning
                    and understanding unit test representations, resulting in improved
                    generation accuracy and code coverage across all the evaluated
                    programming languages.
                </p>
                <div class="paper-links">
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3650212.3680342" class="paper-link"
                        target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2402.03396" class="paper-link" target="_blank">[arXiv]</a>
                </div>
            </div>

            <!-- <div class="publication">
                <h3 class="paper-title">[Paper Title]: [Subtitle or Brief Description]</h3>
                <p class="paper-authors">
                    [Co-author 1], [Co-author 2], <strong>Ethan Wang</strong>, [Co-author 3]
                </p>
                <p class="paper-venue">
                    <em>Preprint</em>, [Year]
                </p>
                <p class="paper-abstract">
                    [Brief abstract or description of the paper. One or two sentences explaining what the paper is about
                    and its main contribution.]
                </p>
                <div class="paper-links">
                    <a href="[arxiv-url]" class="paper-link" target="_blank">[arXiv]</a>
                    <a href="[code-url]" class="paper-link" target="_blank">[Code]</a>
                </div>
            </div> -->
        </section>

        <!-- <section class="projects-section">
            <h2>Research Projects</h2>

            <div class="project">
                <h3>[Project Name]</h3>
                <p class="project-description">
                    [Description of your current or ongoing research project. Explain what you're working on, what
                    methods you're using, and what you hope to discover or achieve.]
                </p>
                <p class="project-collaborators">
                    <strong>Collaborators:</strong> [Collaborator 1], [Collaborator 2]
                </p>
            </div>

            <div class="project">
                <h3>[Project Name]</h3>
                <p class="project-description">
                    [Description of another research project. This could be something you're planning to start or a side
                    project you're exploring.]
                </p>
                <p class="project-collaborators">
                    <strong>Collaborators:</strong> [Collaborator 1]
                </p>
            </div>
        </section> -->
    </main>

    <footer class="footer">
        <p>&copy; <span id="year"></span> Ethan Wang. All rights reserved.</p>
    </footer>

    <script>
        document.getElementById('year').textContent = new Date().getFullYear();
    </script>
</body>

</html>